{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c648555",
   "metadata": {},
   "source": [
    "# CS 378 Homework 4: Mitigation and Model Cards (100 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbdc4a",
   "metadata": {},
   "source": [
    "## Deadline: 11:59 pm, November 7, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70641ec9",
   "metadata": {},
   "source": [
    "This assignment has four parts. First, you will train a model for predicting the creditworthiness of a given individual using the so-called German credit dataset. Second, you will evaluate the model's fairness. Third, you will implement two strategies for the algorithmic mitigation of fairness issues with your model. Finally, you will write a [model card](https://arxiv.org/abs/1810.03993) for a model you trained in the first part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0d93b",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Training a Pytorch model on the German Credit Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5165173",
   "metadata": {},
   "source": [
    "We want you to train your model using Pytorch as this gives you the flexibility to experiment with different kinds of loss functions. Here is the code for loading and cleaning up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3552be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n",
      "       'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9055</td>\n",
       "      <td>36</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>quite rich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2835</td>\n",
       "      <td>24</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>rent</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>6948</td>\n",
       "      <td>36</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>rich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3059</td>\n",
       "      <td>12</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5234</td>\n",
       "      <td>30</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
       "0           0   67    male    2     own             NaN           little   \n",
       "1           1   22  female    2     own          little         moderate   \n",
       "2           2   49    male    1     own          little              NaN   \n",
       "3           3   45    male    2    free          little           little   \n",
       "4           4   53    male    2    free          little           little   \n",
       "5           5   35    male    1    free             NaN              NaN   \n",
       "6           6   53    male    2     own      quite rich              NaN   \n",
       "7           7   35    male    3    rent          little         moderate   \n",
       "8           8   61    male    1     own            rich              NaN   \n",
       "9           9   28    male    3     own          little         moderate   \n",
       "\n",
       "   Credit amount  Duration              Purpose  Risk  \n",
       "0           1169         6             radio/TV  good  \n",
       "1           5951        48             radio/TV   bad  \n",
       "2           2096        12            education  good  \n",
       "3           7882        42  furniture/equipment  good  \n",
       "4           4870        24                  car   bad  \n",
       "5           9055        36            education  good  \n",
       "6           2835        24  furniture/equipment  good  \n",
       "7           6948        36                  car  good  \n",
       "8           3059        12             radio/TV  good  \n",
       "9           5234        30                  car   bad  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "Data = pd.read_csv(\"german_credit_data.csv\")\n",
    "print (Data.columns)\n",
    "Data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf95ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.456548</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>9055</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>2835</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6948</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>3059</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5234</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex  Job  Housing  Saving accounts  Checking account  \\\n",
       "0           0   67  0.0    2      0.0         0.456548          0.000000   \n",
       "1           1   22  1.0    2      0.0         0.000000          1.000000   \n",
       "2           2   49  0.0    1      0.0         0.000000          0.651815   \n",
       "3           3   45  0.0    2      1.0         0.000000          0.000000   \n",
       "4           4   53  0.0    2      1.0         0.000000          0.000000   \n",
       "5           5   35  0.0    1      1.0         0.456548          0.651815   \n",
       "6           6   53  0.0    2      0.0         2.000000          0.651815   \n",
       "7           7   35  0.0    3      2.0         0.000000          1.000000   \n",
       "8           8   61  0.0    1      0.0         3.000000          0.651815   \n",
       "9           9   28  0.0    3      0.0         0.000000          1.000000   \n",
       "\n",
       "   Credit amount  Duration  Purpose  Risk  \n",
       "0           1169         6      0.0   0.0  \n",
       "1           5951        48      0.0   1.0  \n",
       "2           2096        12      1.0   0.0  \n",
       "3           7882        42      2.0   0.0  \n",
       "4           4870        24      3.0   1.0  \n",
       "5           9055        36      1.0   0.0  \n",
       "6           2835        24      2.0   0.0  \n",
       "7           6948        36      3.0   0.0  \n",
       "8           3059        12      0.0   0.0  \n",
       "9           5234        30      3.0   1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Saving accounts'] = Data['Saving accounts'].map({\"little\":0,\"moderate\":1,\"quite rich\":2 ,\"rich\":3 });\n",
    "Data['Saving accounts'] = Data['Saving accounts'].fillna(Data['Saving accounts'].dropna().mean())\n",
    "\n",
    "Data['Checking account'] = Data['Checking account'].map({\"little\":0,\"moderate\":1,\"rich\":2 });\n",
    "Data['Checking account'] = Data['Checking account'].fillna(Data['Checking account'].dropna().mean())\n",
    "\n",
    "Data['Sex'] = Data['Sex'].map({\"male\":0,\"female\":1}).astype(float)\n",
    "\n",
    "Data['Housing'] = Data['Housing'].map({\"own\":0,\"free\":1,\"rent\":2}).astype(float)\n",
    "\n",
    "Data['Purpose'] = Data['Purpose'].map({'radio/TV':0, 'education':1, 'furniture/equipment':2, 'car':3, 'business':4,\n",
    "       'domestic appliances':5, 'repairs':6, 'vacation/others':7}).astype(float)\n",
    "\n",
    "Data['Risk'] = Data['Risk'].map({\"good\":0,\"bad\":1}).astype(float)\n",
    "\n",
    "Data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc649e6",
   "metadata": {},
   "source": [
    "And here is the code for performing a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b968e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "X = Data.drop(columns=['Risk'])\n",
    "Y = Data['Risk']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=137)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117b03c",
   "metadata": {},
   "source": [
    "Now you will use Pytorch to implement a couple of models. Below, we give you some code to translate your training and test data into Pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a304f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "test_x = torch.from_numpy(test_x.astype(np.float32))\n",
    "\n",
    "# Train_y is now a numpy object \n",
    "train_y = list(train_y)\n",
    "\n",
    "# train_y is now a torch object \n",
    "train_y = torch.as_tensor(train_y, dtype = torch.float32)\n",
    "test_y = torch.as_tensor(list(test_y), dtype=torch.float32)\n",
    "\n",
    "train_y = train_y.view(train_y.shape[0],1)\n",
    "test_y = test_y.view(test_y.shape[0],1)\n",
    "\n",
    "n_samples,n_features=train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f06e4c",
   "metadata": {},
   "source": [
    "#### Q1: Consider the unfinished logistic regression model (recall that a logistic regressor is essentially a 1-layer neural network). Finish the model definition by writing the \"forward\" method.  (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24c4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Reg_model(torch.nn.Module):\n",
    " def __init__(self,no_input_features):\n",
    "    super(Logistic_Reg_model,self).__init__()\n",
    "    self.layer1=torch.nn.Linear(no_input_features,20)\n",
    "    self.layer2=torch.nn.Linear(20,1)\n",
    "    self.sigmoid = torch.nn.Sigmoid()\n",
    " def forward(self,x):\n",
    "    # YOUR ANSWER HERE\n",
    "    return self.sigmoid(self.layer2(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7c246",
   "metadata": {},
   "source": [
    "#### Q2:  Now write the training code for the model. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95250956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "epoch 0\n",
      "Epoch: 0 \tTraining Loss: 0.612062 \tValidation Loss: 0.560175\n",
      "epoch 1\n",
      "Epoch: 1 \tTraining Loss: 0.570743 \tValidation Loss: 0.552832\n",
      "epoch 2\n",
      "Epoch: 2 \tTraining Loss: 0.569530 \tValidation Loss: 0.554008\n",
      "epoch 3\n",
      "Epoch: 3 \tTraining Loss: 0.568433 \tValidation Loss: 0.560910\n",
      "epoch 4\n",
      "Epoch: 4 \tTraining Loss: 0.567952 \tValidation Loss: 0.552050\n",
      "epoch 5\n",
      "Epoch: 5 \tTraining Loss: 0.568924 \tValidation Loss: 0.554955\n",
      "epoch 6\n",
      "Epoch: 6 \tTraining Loss: 0.569138 \tValidation Loss: 0.557713\n",
      "epoch 7\n",
      "Epoch: 7 \tTraining Loss: 0.568228 \tValidation Loss: 0.556199\n",
      "epoch 8\n",
      "Epoch: 8 \tTraining Loss: 0.568158 \tValidation Loss: 0.561901\n",
      "epoch 9\n",
      "Epoch: 9 \tTraining Loss: 0.568025 \tValidation Loss: 0.553983\n"
     ]
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    # Create Torch Dataset object.\n",
    "    def __init__(self, X, Y):\n",
    "\n",
    "        #X = X.reshape((-1, 1, 64, 64))  \n",
    "        #self.X = torch.from_numpy(X)\n",
    "        #self.Y = torch.from_numpy(Y)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        Y = self.Y[index]\n",
    "\n",
    "        return {'X': X, 'Y': Y}\n",
    "    \n",
    "# YOUR ANSWER HERE\n",
    "\n",
    "model = Logistic_Reg_model(10)\n",
    "model.train()\n",
    "\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "# FILL IN FOR NONE\n",
    "criterion = torch.nn.BCELoss()\n",
    "# For your optimizer, please include the lr param from section 2.b\n",
    "# and the parameters of the net variable - net.parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "batch_size = 1\n",
    "\n",
    "trainSignData = Dataset(train_x, train_y)\n",
    "trainDataLoader = torch.utils.data.DataLoader(trainSignData, shuffle=True, batch_size=batch_size)\n",
    "testSignData = Dataset(test_x, test_y)\n",
    "testDataLoader = torch.utils.data.DataLoader(testSignData, shuffle=True, batch_size=batch_size)\n",
    "print (\"hey\")\n",
    "def train(epoch, net, trainDataLoader, optimizer, criterion, validDataLoader, intraininglambda=0, train_x=None, train_y=None):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for sample in trainDataLoader:\n",
    "\n",
    "        inputs, targets = sample['X'], sample['Y']\n",
    "        #print (inputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net.forward(inputs)\n",
    "        #print (\"outputs/targets\", outputs, targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        if intraininglambda > 0:\n",
    "            loss += intraininglambda*separationLoss(net, train_x, train_y)\n",
    "        #print (loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print (loss.item())\n",
    "        train_loss += loss.item() * batch_size\n",
    "\n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    for sample in validDataLoader:\n",
    "\n",
    "        inputs, targets = sample['X'], sample['Y']\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_loss += loss.item() * batch_size\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainDataLoader.sampler)\n",
    "    valid_loss = valid_loss/len(validDataLoader.sampler)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "    return train_loss, valid_loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #print (\"hey\")\n",
    "    print (\"epoch\", epoch)\n",
    "    train(epoch, model, trainDataLoader, optimizer, criterion, testDataLoader)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef79d5",
   "metadata": {},
   "source": [
    "Here is some code for testing your model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f249cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300000190734863\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, test_x):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "     y_pred=model(test_x)\n",
    "     y_pred_class=y_pred.round()\n",
    "     accuracy=(y_pred_class.eq(test_y).sum())/float(test_y.shape[0])\n",
    "     print(accuracy.item())\n",
    "accuracy(model, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c968f0f",
   "metadata": {},
   "source": [
    "#### Q3: Now it's time to try out some more complex neural networks! Your goal is to design one that does better, in terms of overall accuracy, than the logistic regression model. You are free to select the architecture of this model as you please. It is also fine you cannot find a model that performs better than the logistic regressor. In that case, please describe the space of models that you tried out in at least 50 words.    (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab054b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 \tTraining Loss: 0.642169 \tValidation Loss: 0.612226\n",
      "epoch 1\n",
      "Epoch: 1 \tTraining Loss: 0.589945 \tValidation Loss: 0.592367\n",
      "epoch 2\n",
      "Epoch: 2 \tTraining Loss: 0.587719 \tValidation Loss: 0.586339\n",
      "epoch 3\n",
      "Epoch: 3 \tTraining Loss: 0.582025 \tValidation Loss: 0.576523\n",
      "epoch 4\n",
      "Epoch: 4 \tTraining Loss: 0.581849 \tValidation Loss: 0.568267\n",
      "epoch 5\n",
      "Epoch: 5 \tTraining Loss: 0.574022 \tValidation Loss: 0.559901\n",
      "epoch 6\n",
      "Epoch: 6 \tTraining Loss: 0.573381 \tValidation Loss: 0.552487\n",
      "epoch 7\n",
      "Epoch: 7 \tTraining Loss: 0.566396 \tValidation Loss: 0.546216\n",
      "epoch 8\n",
      "Epoch: 8 \tTraining Loss: 0.558020 \tValidation Loss: 0.543778\n",
      "epoch 9\n",
      "Epoch: 9 \tTraining Loss: 0.556758 \tValidation Loss: 0.544059\n",
      "epoch 10\n",
      "Epoch: 10 \tTraining Loss: 0.557846 \tValidation Loss: 0.543512\n",
      "epoch 11\n",
      "Epoch: 11 \tTraining Loss: 0.551485 \tValidation Loss: 0.542241\n",
      "epoch 12\n",
      "Epoch: 12 \tTraining Loss: 0.554462 \tValidation Loss: 0.542659\n",
      "epoch 13\n",
      "Epoch: 13 \tTraining Loss: 0.544122 \tValidation Loss: 0.537893\n",
      "epoch 14\n",
      "Epoch: 14 \tTraining Loss: 0.535106 \tValidation Loss: 0.542593\n",
      "DNN Model accuracy: 0.7450000047683716\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "class DNN_model(torch.nn.Module):\n",
    " def __init__(self,no_input_features):\n",
    "    super(DNN_model,self).__init__()\n",
    "    self.layer1=torch.nn.Linear(no_input_features,20)\n",
    "    self.layer2=torch.nn.Linear(20,20)\n",
    "    self.layer3 = torch.nn.Linear(20,20)\n",
    "    self.layer4=torch.nn.Linear(20,1)\n",
    "    \n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    self.dropout = torch.nn.Dropout(p=0.2)\n",
    "    \n",
    "    self.seq = torch.nn.Sequential(\n",
    "        self.layer1,\n",
    "        self.dropout,\n",
    "        self.relu,\n",
    "        self.layer2,\n",
    "        self.dropout,\n",
    "        self.relu,\n",
    "        self.layer3,\n",
    "        self.dropout,\n",
    "        self.relu,\n",
    "        self.layer4\n",
    "    )\n",
    "\n",
    " def forward(self,x):\n",
    "    # YOUR ANSWER HERE\n",
    "    return self.sigmoid(self.seq(x))\n",
    "\n",
    "dnnmodel = DNN_model(10)\n",
    "dnnepochs = 15\n",
    "dnnlr = 5e-4\n",
    "dnnoptimizer = torch.optim.Adam(dnnmodel.parameters(), lr=dnnlr, weight_decay=1e-5)\n",
    "for epoch in range(dnnepochs):\n",
    "    #print (\"hey\")\n",
    "    print (\"epoch\", epoch)\n",
    "    train(epoch, dnnmodel, trainDataLoader, dnnoptimizer, criterion, testDataLoader)\n",
    "\n",
    "torch.save(dnnmodel, \"dnnmodel.pt\")\n",
    "\n",
    "print (\"DNN Model accuracy:\", end = \" \")\n",
    "accuracy(dnnmodel, test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b022550",
   "metadata": {},
   "source": [
    "My Deep Model performed a little better (3%) most of the time, I tried using the leaky relu function istead so as to not completely zero out negative values but that seemed to make it worse.  I also tried adding a residual connection of a adding layer1's output to layer3's output but that didn't help so I took it out. The weight decay in training helped but it didn't make a difference when I added dropout between the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f11a22",
   "metadata": {},
   "source": [
    "## Part 2: Evaluation of Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4e9c6",
   "metadata": {},
   "source": [
    "In the following questions, \"your model\" refers to the best model you discovered in your exploration in Part 1.  We assume \"Sex\" to be the sensitive characteristic $A$ of the input. As in class, $R$ represents the classifier output (is a person predicted to be risky?) and $Y$ represents the ground-truth output (is the person actually risky?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d877ae8",
   "metadata": {},
   "source": [
    "#### Q4: Determine if the model exhibits the property of independence ($R \\perp A$), at least approximately.  Here, \"approximately\" means that $|P(R | A = 0) - P(R | A = 1)| < \\epsilon$. We set $\\epsilon = 0.05$. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f5b73ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female pos prob aka P(R | A = 0): tensor(0.2944, grad_fn=<DivBackward0>)\n",
      "male pos prob aka P(R | A = 1): tensor(0.3720, grad_fn=<DivBackward0>)\n",
      "Does the model satisfy independence:  False\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "def independence(model, data, labels):\n",
    "    \n",
    "    data = pd.DataFrame(data.numpy())\n",
    "    \n",
    "    sexIndex = 2\n",
    "    femaleData = data[data[sexIndex] < 0]\n",
    "    #print (len(femaleData))\n",
    "    \n",
    "    maleData = data[data[sexIndex] > 0]\n",
    "    \n",
    "    #print (len(maleData))\n",
    "    #print (len(data))\n",
    "    \n",
    "    femaleData = torch.tensor(femaleData.values)\n",
    "    maleData = torch.tensor(maleData.values)\n",
    "    \n",
    "    \n",
    "    femalePreds = model(femaleData)\n",
    "    malePreds = model(maleData)\n",
    "    \n",
    "    femalePosProb = (torch.sum(femalePreds)/len(femaleData))\n",
    "    malePosProb = (torch.sum(malePreds)/len(maleData))\n",
    "    \n",
    "    print (\"female pos prob aka P(R | A = 0):\", femalePosProb)\n",
    "    print (\"male pos prob aka P(R | A = 1):\", malePosProb)\n",
    "    independenceLoss = abs(femalePosProb - malePosProb)\n",
    "    \n",
    "\n",
    "    eps = 0.05\n",
    "    return (independenceLoss.item() < eps)\n",
    "    \n",
    "\n",
    "print (\"Does the model satisfy independence: \", independence(dnnmodel, test_x, test_y))\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61515e",
   "metadata": {},
   "source": [
    "#### Q5: Now determine if the model (approximately) satisfies the separation criterion ($R \\perp A | Y$) . Once again, we define approximate separation as $| P(R = r | A = 1, Y = y) - P(R = r | A = 0, Y = y)| < \\epsilon$ where $\\epsilon = 0.05$.  (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c7a5e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|P(R = 1 | A = 1, Y = 0) - P(R = 1 | A = 0, Y = 0)| =  0.010080650448799133\n",
      "|P(R = 1 | A = 1, Y = 1) - P(R = 1 | A = 0, Y = 1)| =  0.10458672046661377\n",
      "Does the model satisfy separation:  False\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "def falseaLossTrueLossSeparationHelper(model, data, labels, verbose=True):\n",
    "    data = pd.DataFrame(data.numpy())\n",
    "    labels = pd.DataFrame(labels.numpy())\n",
    "    sexIndex = 2\n",
    "    xd = data[sexIndex] < 0\n",
    "    dx = (labels == 1).squeeze()\n",
    "\n",
    "    femaleTrueData = data[(data[sexIndex] < 0) & (labels == 1).squeeze()]\n",
    "    femaleFalseData = data[(data[sexIndex] < 0) & (labels == 0).squeeze()]\n",
    "\n",
    "    maleTrueData = data[(data[sexIndex] > 0) & (labels == 1).squeeze()]\n",
    "    maleFalseData = data[(data[sexIndex] > 0) & (labels == 0).squeeze()]\n",
    "    \n",
    "    femaleTrueData = torch.tensor(femaleTrueData.values)\n",
    "    femaleFalseData = torch.tensor(femaleFalseData.values)\n",
    "    \n",
    "    maleTrueData = torch.tensor(maleTrueData.values)\n",
    "    maleFalseData = torch.tensor(maleFalseData.values)\n",
    "    \n",
    "    femaleTruePreds = model(femaleTrueData)\n",
    "    femaleFalsePreds = model(femaleFalseData)\n",
    "    \n",
    "    maleTruePreds = model(maleTrueData)\n",
    "    maleFalsePreds = model(maleFalseData)\n",
    "    \n",
    "    femaleTruePosProb = (torch.sum(femaleTruePreds)/len(femaleTrueData))\n",
    "    femaleFalsePosProb = (torch.sum(femaleFalsePreds)/len(femaleFalseData))\n",
    "    \n",
    "    maleTruePosProb = (torch.sum(maleTruePreds)/len(maleTrueData))\n",
    "    maleFalsePosProb = (torch.sum(maleFalsePreds)/len(maleFalseData))\n",
    "    \n",
    "    #print (femaleTruePosProb, maleTruePosProb, femaleFalsePosProb, maleFalsePosProb)\n",
    "\n",
    "    falseLoss = abs(femaleFalsePosProb - maleFalsePosProb)\n",
    "    trueLoss = abs(femaleTruePosProb - maleTruePosProb)\n",
    "    if verbose:\n",
    "        print (\"|P(R = 1 | A = 1, Y = 0) - P(R = 1 | A = 0, Y = 0)| = \", falseLoss.item())\n",
    "        print (\"|P(R = 1 | A = 1, Y = 1) - P(R = 1 | A = 0, Y = 1)| = \", trueLoss.item())\n",
    "    return falseLoss, trueLoss\n",
    "    \n",
    "def maxSeparation(model, data, labels):\n",
    "    res = falseaLossTrueLossSeparationHelper(model, data, labels)\n",
    "    return max(res[0].item(), res[1].item())\n",
    "    \n",
    "def separation(model, data, labels):\n",
    "    maxSep = maxSeparation(model, data, labels)\n",
    "    eps = 0.05\n",
    "    return (maxSep < eps)\n",
    "\n",
    "def separationLoss(model, data, labels):\n",
    "    falseLoss, trueLoss = falseaLossTrueLossSeparationHelper(model, data, labels, verbose=False)\n",
    "    return falseLoss + trueLoss\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print (\"Does the model satisfy separation: \", separation(dnnmodel, test_x, test_y))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2672a97",
   "metadata": {},
   "source": [
    "#### Q6: Finally, determine if the model (approximately) satisfies the sufficiency criterion $(A \\perp Y | R)$. Approximate sufficiency is defined in a similar way as in Q4 and Q5. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "131fde1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the model satisfy sufficiency:  False\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "def sufficiency(model, data, labels):\n",
    "    \n",
    "    preds = pd.DataFrame(model(data).round().detach().numpy()).squeeze()\n",
    "    data = pd.DataFrame(data.numpy())\n",
    "    labels = pd.DataFrame(labels.numpy()).squeeze()\n",
    "    \n",
    "    predFalseData = data[preds == 0]\n",
    "    predFalseLabels = labels[preds == 0]\n",
    "    predTrueData = data[preds == 1]\n",
    "    predTrueLabels = labels[preds == 1]\n",
    "    \n",
    "    sexIndex = 2\n",
    "    \n",
    "    predFalseY0Data = predFalseData[predFalseLabels == 0]\n",
    "    predFalseY1Data = predFalseData[predFalseLabels == 1]    \n",
    "    xd = predFalseY0Data[sexIndex].value_counts()\n",
    "    femaleCode = xd.keys()[0]\n",
    "    maleCode = xd.keys()[1]\n",
    "    probFemalePredFalseY0 = xd[femaleCode]/(xd[femaleCode] + xd[maleCode])\n",
    "    \n",
    "    xd = predFalseY1Data[sexIndex].value_counts()\n",
    "    probFemalePredFalseY1 = xd[femaleCode]/(xd[femaleCode] + xd[maleCode])\n",
    "    \n",
    "    predFalseSufficiencyLoss = abs(probFemalePredFalseY0 - probFemalePredFalseY1) # making sure A approx indep of Y\n",
    "    \n",
    "    \n",
    "    predTrueY0Data = predTrueData[predTrueLabels == 0]\n",
    "    predTrueY1Data = predTrueData[predTrueLabels == 1]\n",
    "    xd = predTrueY0Data[sexIndex].value_counts()\n",
    "    femaleCode = xd.keys()[0]\n",
    "    maleCode = xd.keys()[1]\n",
    "    probFemalePredTrueY0 = xd[femaleCode]/(xd[femaleCode] + xd[maleCode])\n",
    "    \n",
    "    xd = predTrueY1Data[sexIndex].value_counts()\n",
    "    probFemalePredTrueY1 = xd[femaleCode]/(xd[femaleCode] + xd[maleCode])\n",
    "    \n",
    "    \n",
    "    predTrueSufficiencyLoss = abs(probFemalePredTrueY0 - probFemalePredTrueY1)\n",
    "    \n",
    "    #print (probFemalePredFalseY0, probFemalePredFalseY1, probFemalePredTrueY0, probFemalePredTrueY1)\n",
    "    eps = 0.05\n",
    "    return (predFalseSufficiencyLoss < eps and predTrueSufficiencyLoss < eps).item()\n",
    "    \n",
    "print (\"Does the model satisfy sufficiency: \", sufficiency(dnnmodel, test_x, test_y))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba8c38",
   "metadata": {},
   "source": [
    "## Part 3: Fairness Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94852909",
   "metadata": {},
   "source": [
    "#### Q7: Your goal now is to implement the preprocessing (dataset repair) strategy for mitigating fairness that we discussed in class. Specifically, note that your model assigns a numerical score to each input. Rewrite these scores so that when you threshold on the new scores, the resulting classifiers will satisfy the separation criterion (approximately).         (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6715840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print (test_x)\\nprint (\"---------\")\\nprint (newtest_x)'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculatePercentile(arr, x):\n",
    "    low = 0\n",
    "    high = len(arr)\n",
    "    while low + 1 < high:\n",
    "        mid = low + (high - low)//2\n",
    "        if arr[mid] <= x:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "    \n",
    "    return low/len(arr) # techinically percentile/100\n",
    "        \n",
    "def convertDataset(data, valsToSortedList):\n",
    "    sexIndex = 2\n",
    "    #print (data)\n",
    "    #print (valsToSortedList)\n",
    "    for dataCounter in range(len(data)):\n",
    "        #row = data.iloc[dataCounter]\n",
    "        if data.at[dataCounter, sexIndex] < 0: # female\n",
    "            for i in range(10):\n",
    "                if i == sexIndex:\n",
    "                    continue\n",
    "                percentile = calculatePercentile(valsToSortedList[0][i], data.at[dataCounter, i])\n",
    "                femaleValue = data.at[dataCounter, i]\n",
    "                maleValue = valsToSortedList[1][i][int(percentile * len(valsToSortedList[1][i]))]\n",
    "                median = (femaleValue + maleValue)/2 # also happens to be average\n",
    "                #print (femaleValue, median)\n",
    "                #row[i] = median\n",
    "                data.at[dataCounter, i] = median\n",
    "                #print (row[i], data.iloc[dataCounter][i])\n",
    "                #if femaleValue != median:\n",
    "                #    print (femaleValue, median, data.iloc[dataCounter][i])\n",
    "        else: # male\n",
    "            for i in range(10):\n",
    "                if i == sexIndex:\n",
    "                    continue\n",
    "                percentile = calculatePercentile(valsToSortedList[1][i], data.at[dataCounter, i])\n",
    "                maleValue = data.at[dataCounter, i]\n",
    "                femaleValue = valsToSortedList[0][i][int(percentile * len(valsToSortedList[0][i]))]\n",
    "                median = (femaleValue + maleValue)/2 # also happens to be average\n",
    "                #row[i] = median\n",
    "                data.at[dataCounter, i] = median\n",
    "    return data\n",
    "                \n",
    "def datasetrepair(data):\n",
    "    \n",
    "    # data preprocessing, slide 98 of the fairness slides\n",
    "    \n",
    "    #print (data.shape)\n",
    "    #data = pd.DataFrame(data.numpy())\n",
    "    #print (data)\n",
    "\n",
    "    sexIndex = 2\n",
    "    femaleData = data[data[sexIndex] < 0]\n",
    "    #print (len(femaleData))\n",
    "\n",
    "    maleData = data[data[sexIndex] > 0]\n",
    "    \n",
    "    valsToSortedList = defaultdict(lambda: dict()) # maps sensitive attribute value to a map of columns to sorted lists\n",
    "    #print (femaleData[2].to_numpy().tolist())\n",
    "    for i in range(10):\n",
    "        if i == 2:\n",
    "            continue\n",
    "        col = data[i]\n",
    "        \n",
    "        femaleCol = femaleData[i].to_numpy().tolist()\n",
    "        femaleCol.sort()\n",
    "        maleCol = maleData[i].to_numpy().tolist()\n",
    "        maleCol.sort()\n",
    "        valsToSortedList[0][i] = femaleCol\n",
    "        valsToSortedList[1][i] = maleCol\n",
    "        \n",
    "    newdata = convertDataset(data.copy(), valsToSortedList)\n",
    "    return newdata, valsToSortedList\n",
    "\n",
    "from copy import deepcopy\n",
    "#print (\"before:\\n\", test_x)\n",
    "newtrain_x, valsToSortedList = datasetrepair(pd.DataFrame(deepcopy(train_x).numpy())) # the medians/percentiles will be based off the train set\n",
    "newtest_x = convertDataset(pd.DataFrame(deepcopy(test_x).numpy()), valsToSortedList) # apply the training set medians/percentiles to the test set\n",
    "newtrain_x = torch.tensor(newtrain_x.values).float()\n",
    "newtest_x = torch.tensor(newtest_x.values).float()\n",
    "\n",
    "'''print (newtest_x)'''\n",
    "\n",
    "\n",
    "'''print (test_x)\n",
    "print (\"---------\")\n",
    "print (newtest_x)'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e045f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 \tTraining Loss: 0.670192 \tValidation Loss: 0.608502\n",
      "epoch 1\n",
      "Epoch: 1 \tTraining Loss: 0.604473 \tValidation Loss: 0.595125\n",
      "epoch 2\n",
      "Epoch: 2 \tTraining Loss: 0.595169 \tValidation Loss: 0.589142\n",
      "epoch 3\n",
      "Epoch: 3 \tTraining Loss: 0.594211 \tValidation Loss: 0.583797\n",
      "epoch 4\n",
      "Epoch: 4 \tTraining Loss: 0.586173 \tValidation Loss: 0.579704\n",
      "epoch 5\n",
      "Epoch: 5 \tTraining Loss: 0.585194 \tValidation Loss: 0.578421\n",
      "epoch 6\n",
      "Epoch: 6 \tTraining Loss: 0.570033 \tValidation Loss: 0.571879\n",
      "epoch 7\n",
      "Epoch: 7 \tTraining Loss: 0.576002 \tValidation Loss: 0.571544\n",
      "epoch 8\n",
      "Epoch: 8 \tTraining Loss: 0.571248 \tValidation Loss: 0.569176\n",
      "epoch 9\n",
      "Epoch: 9 \tTraining Loss: 0.581584 \tValidation Loss: 0.566379\n",
      "epoch 10\n",
      "Epoch: 10 \tTraining Loss: 0.564305 \tValidation Loss: 0.565252\n",
      "epoch 11\n",
      "Epoch: 11 \tTraining Loss: 0.563829 \tValidation Loss: 0.558052\n",
      "epoch 12\n",
      "Epoch: 12 \tTraining Loss: 0.565980 \tValidation Loss: 0.552156\n",
      "epoch 13\n",
      "Epoch: 13 \tTraining Loss: 0.544339 \tValidation Loss: 0.545850\n",
      "epoch 14\n",
      "Epoch: 14 \tTraining Loss: 0.558089 \tValidation Loss: 0.545219\n"
     ]
    }
   ],
   "source": [
    "fairTrainSignData = Dataset(newtrain_x, train_y)\n",
    "fairTrainDataLoader = torch.utils.data.DataLoader(fairTrainSignData, shuffle=True, batch_size=batch_size)\n",
    "fairTestSignData = Dataset(newtest_x, test_y)\n",
    "fairTestDataLoader = torch.utils.data.DataLoader(fairTestSignData, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "fairdnnmodel = DNN_model(10)\n",
    "fairdnnoptimizer = torch.optim.Adam(fairdnnmodel.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "for epoch in range(15):\n",
    "    #print (\"hey\")\n",
    "    print (\"epoch\", epoch)\n",
    "    train(epoch, fairdnnmodel, fairTrainDataLoader, fairdnnoptimizer, criterion, fairTestDataLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5672b",
   "metadata": {},
   "source": [
    "#### Q8: Compute the overall accuracy of the fairness-mitigated model obtained in your answer to Q7. Repeat your analysis of independence, separation, and sufficiency, previously performed in your answers to Q4-Q6, on this model.    (5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "76be6d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fair DNN Model accuracy:  0.75\n",
      "female pos prob aka P(R | A = 0): tensor(0.2893, grad_fn=<DivBackward0>)\n",
      "male pos prob aka P(R | A = 1): tensor(0.3718, grad_fn=<DivBackward0>)\n",
      "Does the model satisfy independence:  False\n",
      "|P(R = 1 | A = 1, Y = 0) - P(R = 1 | A = 0, Y = 0)| =  0.028803735971450806\n",
      "|P(R = 1 | A = 1, Y = 1) - P(R = 1 | A = 0, Y = 1)| =  0.11915519833564758\n",
      "Does the model satisfy separation:  False\n",
      "Does the model satisfy sufficiency:  False\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "# Save the model\n",
    "torch.save(model, \"fairdnnmodel.pt\")\n",
    "print (\"Fair DNN Model accuracy: \", end = \" \")\n",
    "accuracy(fairdnnmodel, newtest_x)\n",
    "print (\"Does the model satisfy independence: \", independence(fairdnnmodel, newtest_x, test_y))\n",
    "print (\"Does the model satisfy separation: \", separation(fairdnnmodel, newtest_x, test_y))\n",
    "print (\"Does the model satisfy sufficiency: \", sufficiency(fairdnnmodel, newtest_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3cde8",
   "metadata": {},
   "source": [
    "My fair dnn model with preprocessed data only sometimes satisfies separation (depending on the run, probably has to do with the random seed).  However, the probabilities are much closer compared to the those of regular dnn model without the preprocessed data, so it is definitely making a lot closer to satisfying separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01935fb",
   "metadata": {},
   "source": [
    "#### Q9: Now we would like you to implement the in-training strategy for fairness mitigation that we discussed in class. Your goal is to ensure the separation criterion. Suitably modify the loss function of your model to capture this goal (approximately), and retrain your model.    (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d147d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 \tTraining Loss: 0.643618 \tValidation Loss: 0.610069\n",
      "epoch 1\n",
      "Epoch: 1 \tTraining Loss: 0.605589 \tValidation Loss: 0.593865\n",
      "epoch 2\n",
      "Epoch: 2 \tTraining Loss: 0.597293 \tValidation Loss: 0.585022\n",
      "epoch 3\n",
      "Epoch: 3 \tTraining Loss: 0.592486 \tValidation Loss: 0.575134\n",
      "epoch 4\n",
      "Epoch: 4 \tTraining Loss: 0.577412 \tValidation Loss: 0.566276\n",
      "epoch 5\n",
      "Epoch: 5 \tTraining Loss: 0.584024 \tValidation Loss: 0.564551\n",
      "epoch 6\n",
      "Epoch: 6 \tTraining Loss: 0.581707 \tValidation Loss: 0.566384\n",
      "epoch 7\n",
      "Epoch: 7 \tTraining Loss: 0.581495 \tValidation Loss: 0.566173\n",
      "epoch 8\n",
      "Epoch: 8 \tTraining Loss: 0.572393 \tValidation Loss: 0.566446\n",
      "epoch 9\n",
      "Epoch: 9 \tTraining Loss: 0.574116 \tValidation Loss: 0.566293\n",
      "epoch 10\n",
      "Epoch: 10 \tTraining Loss: 0.567896 \tValidation Loss: 0.567272\n",
      "epoch 11\n",
      "Epoch: 11 \tTraining Loss: 0.567201 \tValidation Loss: 0.565825\n",
      "epoch 12\n",
      "Epoch: 12 \tTraining Loss: 0.566239 \tValidation Loss: 0.571501\n",
      "epoch 13\n",
      "Epoch: 13 \tTraining Loss: 0.565620 \tValidation Loss: 0.571690\n",
      "epoch 14\n",
      "Epoch: 14 \tTraining Loss: 0.564060 \tValidation Loss: 0.572944\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "fairintrainingdnnmodel = DNN_model(10)\n",
    "dnnepochs = 15\n",
    "dnnlr = 5e-4\n",
    "fairintrainingdnnoptimizer = torch.optim.Adam(fairintrainingdnnmodel.parameters(), lr=dnnlr, weight_decay=1e-5)\n",
    "fairintrainingcriterion = torch.nn.BCELoss()\n",
    "for epoch in range(dnnepochs):\n",
    "    #print (\"hey\")\n",
    "    print (\"epoch\", epoch)\n",
    "    # uses the optional parameter intraininglambda to indicate that the separationLoss needs to be added to BCELoss\n",
    "    train(epoch, fairintrainingdnnmodel, fairTrainDataLoader, fairintrainingdnnoptimizer, fairintrainingcriterion, fairTestDataLoader, intraininglambda=5, train_x=train_x, train_y=train_y)\n",
    "\n",
    "torch.save(fairintrainingdnnmodel, \"fairintrainingdnnmodel.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9fd23",
   "metadata": {},
   "source": [
    "#### Q10: Compute the overall accuracy of the model obtained in your answer to Q9. Repeat your analysis of independence, separation, and sufficiency, previously performed in your answers to Q4-Q6, on this model.   (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a6edcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fair in-training DNN Model accuracy: 0.7300000190734863\n",
      "female pos prob aka P(R | A = 0): tensor(0.3123, grad_fn=<DivBackward0>)\n",
      "male pos prob aka P(R | A = 1): tensor(0.3595, grad_fn=<DivBackward0>)\n",
      "Does the model satisfy independence:  True\n",
      "|P(R = 1 | A = 1, Y = 0) - P(R = 1 | A = 0, Y = 0)| =  0.011290639638900757\n",
      "|P(R = 1 | A = 1, Y = 1) - P(R = 1 | A = 0, Y = 1)| =  0.06934034824371338\n",
      "Does the model satisfy separation:  False\n",
      "Does the model satisfy sufficiency:  False\n"
     ]
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "print (\"Fair in-training DNN Model accuracy:\", end = \" \")\n",
    "accuracy(fairintrainingdnnmodel, test_x)\n",
    "print (\"Does the model satisfy independence: \", independence(fairintrainingdnnmodel, newtest_x, test_y))\n",
    "print (\"Does the model satisfy separation: \", separation(fairintrainingdnnmodel, newtest_x, test_y))\n",
    "print (\"Does the model satisfy sufficiency: \", sufficiency(fairintrainingdnnmodel, newtest_x, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd19474",
   "metadata": {},
   "source": [
    "#### Q11: Comment on the tradeoffs between overall accuracy and fairness that you see in your experimental exploration above. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04229cef",
   "metadata": {},
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "I actually expected to see worse accuracy when fairness was put in (as the model now needs to optimize something besides just accuracy), but this was not the case.  I guess the model was able to find solutions that are fair and just as accurate as before, but it needs a push in the right direction to find fair solutions.  Especially for the in-training separation loss model, the validation loss and accuracy were surprisingly low.  However, I did notice some variation run to run on all the models (maybe around 1-2% variance).  Still, I ran them numerous times and found great/similar results from all the models.  I needed to make the lambda for the intraining model higher than I expected (I chose 5 because in the end I was getting validation loss of like 0.55 and separation losses of about 0.1 and I wanted them to be about equal).  The intraining model was veryyy close to passing our 0.05 margin for separation.  Interestingly, independence passed with the addition of this loss function and accuracy was not compromised.  Finally, I actually made the intraining model use the preprocessed data (which may have been the intention of the lab, not sure) which reduced the maximum separation distance to 0.069, which is just 0.019 over our limit.  Accuracy was still not compromised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5a3a6",
   "metadata": {},
   "source": [
    "## Part 4: Writing a Model Card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73511f",
   "metadata": {},
   "source": [
    "#### Q12: Write a model card, following the format shown in the original [Mitchell et al.](https://arxiv.org/pdf/1810.03993.pdf) paper, for your model. Templates are available in Figures 2 and 3 of the paper.   (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182956a",
   "metadata": {},
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "Model Details:\n",
    "Deep Neural Network with 10 input features, 3 hidden layers of 20 nodes each, followed by a dropout and relu.  Lastly, an output layer of one node and then a sigmoid.  Intended use is predicting credit risk among people, while being fair against the sensitive attribute (gender).\n",
    "\n",
    "Trained using Binary Cross Entropy Loss, with weight decay 1e-5, learning rate 5e-4. Fairness metrics given and separation used in training.  Separation was added to the training loss, which slowed down training but made the model virtually pass separation (depending on run).\n",
    "\n",
    "Metrics: Independence, Separation, and Sufficiency of the model.\n",
    "\n",
    "Data: 800 samples of people with good/bad credit risk.  Data had a class imbalance of vastly more good examples (about 10:1).  Data was preprocessed via replacing all nonsensitive features with taking the median value (among all sensitive groups) at the percentile among this group.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5dd69a",
   "metadata": {},
   "source": [
    "#### Q13 (OPTIONAL): How difficult was this homework and how many hours did you spend on it? (0 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5676c6f",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
